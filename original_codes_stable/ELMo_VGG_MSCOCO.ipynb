{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1024 11:16:47.920156 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/native_module.py:54: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow_hub as hub\n",
    "from utils import *\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config = tf.ConfigProto(gpu_options=gpu_options,log_device_placement=True,allow_soft_placement=True)\n",
    "import lmdb\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "#data_path = '../data/mscoco/'\n",
    "data_path = '/dvmm-filer2/datasets/Groundings/data/mscoco/'\n",
    "dict_paths = [data_path+'train2014.pickle',\n",
    "              data_path+'val2014.pickle'] \n",
    "lmdb_path = data_path+'MSCOCO_jpg.lmdb'\n",
    "\n",
    "#loading mscoco data\n",
    "lmdb_env = lmdb.open(lmdb_path, map_size=int(1e11), readonly=True, lock=False)\n",
    "txn = lmdb_env.begin(write=False)\n",
    "\n",
    "with open(dict_paths[0], 'rb') as f:\n",
    "    dict_train = pickle.load(f, encoding='latin1')\n",
    "    ids_train = list(dict_train.keys())\n",
    "    \n",
    "with open(dict_paths[1], 'rb') as f:\n",
    "    dict_val = pickle.load(f, encoding='latin1')\n",
    "    ids_val = list(dict_val.keys())\n",
    "\n",
    "#f30k_path = '../data/flickr30k/'\n",
    "f30k_path = '/dvmm-filer2/datasets/Groundings/data/flickr30k/'\n",
    "f30k_dict_path = f30k_path+'flickr30k_val.pickle'\n",
    "\n",
    "#loading flickr30k data\n",
    "with open(f30k_dict_path, 'rb') as f:\n",
    "    dict_val = pickle.load(f, encoding='latin1')    \n",
    "\n",
    "n_batch = 32\n",
    "gamma_1 = 5.0\n",
    "gamma_2 = 10.0\n",
    "n_iter_per_epoch = int(len(dict_train)/n_batch)\n",
    "n_iter_per_epoch_val = int(len(dict_val)/n_batch)\n",
    "n_epochs = 20 #N of epochs\n",
    "reg_val = .0005\n",
    "num_tst = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_correctness(annot,heatmap,orig_img_shape):\n",
    "    bbox_dict = heat2bbox(heatmap,orig_img_shape)\n",
    "    bbox, bbox_norm, bbox_score = filter_bbox(bbox_dict=bbox_dict, order='xyxy')\n",
    "    bbox_norm_annot = union(annot['bbox_norm'])\n",
    "    bbox_annot = annot['bbox']\n",
    "    bbox_norm_pred = union(bbox_norm)\n",
    "    bbox_correctness = isCorrect(bbox_norm_annot, bbox_norm_pred, iou_thr=.5)\n",
    "    hit_correctness = isCorrectHit(bbox_annot,heatmap,orig_img_shape)\n",
    "    return bbox_correctness,hit_correctness\n",
    "\n",
    "def validate_flickr30k(dict_test):\n",
    "    cnt_overall = 0\n",
    "    cnt_correct = 0\n",
    "    cnt_correct_hit = 0\n",
    "    for k,doc_id in enumerate(dict_test):\n",
    "        if k>num_tst:\n",
    "            continue\n",
    "        img = np.reshape(cv2.resize(dict_test[doc_id]['img'],(299,299)),(1,299,299,3))\n",
    "        orig_img_shape = dict_test[doc_id]['size']\n",
    "        sen_batch = list(dict_test[doc_id]['sentences'].keys())\n",
    "        img_batch = np.repeat(img,len(sen_batch),axis=0)\n",
    "        tensor_list = [heatmap_w, R_i, R_s]\n",
    "        feed_dict = {input_img: img_batch, text_batch: sen_batch, mode: 'test'}\n",
    "        qry_heats, qry_scores, sen_score = sess.run(tensor_list, feed_dict)\n",
    "        for c,sen in enumerate(sen_batch):\n",
    "            for query in dict_test[doc_id]['sentences'][sen]:\n",
    "                #reject not groundable/acceptable queries\n",
    "                idx = dict_test[doc_id]['sentences'][sen][query]['idx']\n",
    "                if len(query.split())==0 or len(idx)==0:\n",
    "                    continue\n",
    "                annot = dict_test[doc_id]['sentences'][sen][query]\n",
    "                category = annot['category']\n",
    "                if 'notvisual' in category or len(annot['bbox_norm'])==0:\n",
    "                    continue\n",
    "                if not check_percent(union(annot['bbox_norm'])):\n",
    "                    continue\n",
    "                #if reaches this point, it is groundable/acceptable\n",
    "                cnt_overall+=1\n",
    "\n",
    "                if np.mean(qry_scores[c,idx])==0:\n",
    "                    pred = {}\n",
    "                else:\n",
    "                    heatmap = np.average(qry_heats[c,idx,:], weights = qry_scores[c,idx], axis=0)\n",
    "                    bbox_c,hit_c = calc_correctness(annot,heatmap,orig_img_shape)\n",
    "                    cnt_correct+=bbox_c\n",
    "                    cnt_correct_hit+=hit_c\n",
    "                    \n",
    "        var = [k,num_tst,cnt_correct/cnt_overall,cnt_correct_hit/cnt_overall]\n",
    "        prnt = 'Sample {}/{}, IoU_acc:{:.2f}, Hit_acc:{:.2f} \\r'.format(var[0],var[1],var[2],var[3])\n",
    "        sys.stdout.write(prnt)                \n",
    "        sys.stdout.flush()\n",
    "\n",
    "    hit_acc = cnt_correct_hit/cnt_overall\n",
    "    iou_acc = cnt_correct/cnt_overall\n",
    "    return iou_acc,hit_acc\n",
    "\n",
    "def batch_gen(ids, annot_dict, txn):\n",
    "    img_batch = np.empty((n_batch, 299, 299, 3), dtype='float32')\n",
    "    cap_batch = []\n",
    "    #currently, it takes negative samples randomly from \"all\" dataset\n",
    "    #it randomly picks any batch, so it doesn't have ending\n",
    "    seen = {}\n",
    "    for i in range(n_batch):\n",
    "        choice_id = random.choice(ids)\n",
    "        while choice_id in seen: #we don't want to have repetitive img/caps in a batch \n",
    "            choice_id = random.choice(ids)\n",
    "        imgbin = txn.get(choice_id.encode('utf-8'))\n",
    "        buff = np.frombuffer(imgbin, dtype='uint8')\n",
    "        while choice_id in seen or len(buff)==0:\n",
    "            choice_id = random.choice(ids)\n",
    "            imgbin = txn.get(choice_id.encode('utf-8'))\n",
    "            buff = np.frombuffer(imgbin, dtype='uint8')\n",
    "        seen[choice_id] = 1\n",
    "        \n",
    "        imgbgr = cv2.imdecode(buff, cv2.IMREAD_COLOR)\n",
    "        img = imgbgr[:,:,[2,1,0]]\n",
    "        img_batch[i,:,:,:] = cv2.resize(img,(299,299))\n",
    "\n",
    "        sentence = random.choice(annot_dict[choice_id]['sentences'])\n",
    "        cap_batch.append(sentence)\n",
    "    return img_batch, cap_batch\n",
    "\n",
    "def attn_loss(e_w,v,e_s):\n",
    "    #e: ?xTxD, v: ?xNx4xD, e_bar: ?xD\n",
    "    with tf.variable_scope('attention_loss'):\n",
    "        ###word-level###\n",
    "        #heatmap\n",
    "        h = tf.nn.relu(tf.einsum('bij,cklj->bcikl',e_w,v)) #pair-wise ev^T: ?x?xTxNx4\n",
    "        #attention\n",
    "        a = tf.einsum('bcijl,cjlk->bcikl',h,v) #?x?xTxDx4 attnded visual reps for each of T words for all pairs\n",
    "        #pair-wise score\n",
    "        a_norm = tf.nn.l2_normalize(a,axis=3)\n",
    "        e_w_norm = tf.nn.l2_normalize(e_w,axis=2)\n",
    "        R_ik = tf.einsum('bcilk,bil->bcik',a_norm,e_w_norm) #cosine for T (words,img_reps) for all pairs\n",
    "        #level dropout\n",
    "        #R_ik_sh = R_ik.get_shape().as_list()\n",
    "        #R_ik = tf.layers.dropout(R_ik,rate=0.5,noise_shape=[1,1,1,R_ik_sh[3]],\n",
    "        #                         training=isTraining)\n",
    "        R_i = tf.reduce_max(R_ik,axis=-1) #?x?xT\n",
    "        R = tf.log(tf.pow(tf.reduce_sum(tf.exp(gamma_1*R_i),axis=2),1/gamma_1)) #?x? cap-img pairs\n",
    "        #posterior probabilities\n",
    "        P_DQ = tf.diag_part(tf.nn.softmax(gamma_2*R,axis=0)) #P(cap match img)\n",
    "        P_QD = tf.diag_part(tf.nn.softmax(gamma_2*R,axis=1)) #p(img match cap)\n",
    "        #losses\n",
    "        L1_w = -tf.reduce_mean(tf.log(P_DQ))\n",
    "        L2_w = -tf.reduce_mean(tf.log(P_QD))\n",
    "        \n",
    "        ###sentence-level###\n",
    "        #heatmap\n",
    "        h_s = tf.nn.relu(tf.einsum('bj,cklj->bckl',e_s,v)) #pair-wise e_bar*v^T: ?x?xNx4\n",
    "        #attention\n",
    "        a_s = tf.einsum('bcjk,cjkl->bclk',h_s,v) #?x?xDx4 attnded visual reps for sen. for all pairs\n",
    "        #pair-wise score\n",
    "        a_s_norm = tf.nn.l2_normalize(a_s,axis=2)\n",
    "        e_s_norm = tf.nn.l2_normalize(e_s,axis=1)\n",
    "        R_sk = tf.einsum('bclk,bl->bck',a_s_norm,e_s_norm) #cosine for (sen,img_reps) for all pairs\n",
    "        R_s = tf.reduce_max(R_sk,axis=-1) #?x?\n",
    "        #posterior probabilities\n",
    "        P_DQ_s = tf.diag_part(tf.nn.softmax(gamma_2*R_s,axis=0)) #P(cap match img)\n",
    "        P_QD_s = tf.diag_part(tf.nn.softmax(gamma_2*R_s,axis=1)) #P(img match cap)\n",
    "        #losses\n",
    "        L1_s = -tf.reduce_mean(tf.log(P_DQ_s))\n",
    "        L2_s = -tf.reduce_mean(tf.log(P_QD_s))\n",
    "        #overall loss\n",
    "        loss = L1_w + L2_w + L1_s + L2_s\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "def attn(e_w,v,e_s):\n",
    "    ## Inputs: local and global cap and img features ##\n",
    "    ## Output: Heatmap for each word, Global Heatmap, Attnded Vis features, Corr-vals\n",
    "    #e: ?xTxD, v: ?xNx4xD, e_bar: ?xD\n",
    "    with tf.variable_scope('attention'):\n",
    "        ###word-level###\n",
    "        #heatmap pool\n",
    "        h = tf.nn.relu(tf.einsum('bij,bklj->bikl',e_w,v)) #pair-wise ev^T: ?xTxNx4\n",
    "        #attention\n",
    "        a = tf.einsum('bijk,bjkl->bilk',h,v) #?xTxDx4 attnded visual reps for each of T words\n",
    "        #pair-wise score\n",
    "        a_norm = tf.nn.l2_normalize(a,axis=2)\n",
    "        e_w_norm = tf.nn.l2_normalize(e_w,axis=2)\n",
    "        R_ik = tf.einsum('bilk,bil->bik',a_norm,e_w_norm) #cosine for T (words,img_reps) for all pairs\n",
    "        R_ik = tf.identity(R_ik,name='level_score_word')\n",
    "        R_i = tf.reduce_max(R_ik,axis=-1,name='score_word') #?xT\n",
    "        #R = tf.log(tf.pow(tf.reduce_sum(tf.exp(gamma_1*R_i),axis=1),1/gamma_1)) #? corrs\n",
    "        #heatmap\n",
    "        idx_i = tf.argmax(R_ik,axis=-1,name='level_index_word') #?xT index of the featuremap which maximizes R_i\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.summary.histogram('histogram_w', idx_i)\n",
    "        ii,jj = tf.meshgrid(tf.range(tf.shape(idx_i)[0]),tf.range(tf.shape(idx_i)[1]),indexing='ij')\n",
    "        ii = tf.cast(ii,tf.int64)\n",
    "        jj = tf.cast(jj,tf.int64)\n",
    "        batch_idx_i = tf.stack([tf.reshape(ii,(-1,)),\n",
    "                                tf.reshape(jj,(-1,)),\n",
    "                                tf.reshape(idx_i,(-1,))],axis=1) #?Tx3 indices of argmax\n",
    "        N0=int(np.sqrt(h.get_shape().as_list()[2]))\n",
    "        h_max = tf.gather_nd(tf.transpose(h,[0,1,3,2]),batch_idx_i) #?TxN retrieving max heatmaps\n",
    "        heatmap_wd = tf.reshape(h_max,[tf.shape(h)[0],tf.shape(h)[1],N0,N0],name='heatmap_word')\n",
    "        heatmap_wd_l = tf.reshape(h,[tf.shape(h)[0],tf.shape(h)[1],N0,N0,tf.shape(h)[3]],name='level_heatmap_word')\n",
    "        \n",
    "        ###sentence-level###\n",
    "        #heatmap pool\n",
    "        h_s = tf.nn.relu(tf.einsum('bj,blkj->blk',e_s,v)) #pair-wise e_bar*v^T: ?xNx4\n",
    "        #attention\n",
    "        a_s = tf.einsum('bjk,bjki->bik',h_s,v) #?xDx4 attnded visual reps for sen.\n",
    "        #pair-wise score\n",
    "        a_s_norm = tf.nn.l2_normalize(a_s,axis=1)\n",
    "        e_s_norm = tf.nn.l2_normalize(e_s,axis=1)\n",
    "        R_sk = tf.einsum('bik,bi->bk',a_s_norm,e_s_norm) #cosine for (sen,img_reps)\n",
    "        R_sk = tf.identity(R_sk,name='level_score_sentence')\n",
    "        R_s = tf.reduce_mean(R_sk,axis=-1,name='score_sentence') #?\n",
    "        #heatmap\n",
    "        idx_k = tf.argmax(R_sk,axis=-1,name='level_index_sentence') #? index of the featuremap which maximizes R_i\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.summary.histogram('histogram_s', idx_k)\n",
    "        ii_k = tf.cast(tf.range(tf.shape(idx_k)[0]),dtype='int64')\n",
    "        batch_idx_k = tf.stack([ii_k,idx_k],axis=1)\n",
    "        N0_g=int(np.sqrt(h_s.get_shape().as_list()[1]))\n",
    "        h_s_max = tf.gather_nd(tf.transpose(h_s,[0,2,1]),batch_idx_k) #?xN retrieving max heatmaps\n",
    "        heatmap_sd = tf.reshape(h_s_max,[-1,N0_g,N0_g],name='heatmap_sentence')\n",
    "        heatmap_sd_l = tf.reshape(h_s,[-1,N0_g,N0_g,tf.shape(h)[3]],name='level_heatmap_sentence')\n",
    "        \n",
    "    return heatmap_wd, heatmap_sd, R_i, R_s  \n",
    "\n",
    "def add_1by1_conv(feat_map,n_layers,n_filters,name,regularizer):\n",
    "    with tf.variable_scope(name+'_postConv'):\n",
    "        for i in range(n_layers):\n",
    "            with tf.variable_scope(name+'_stage_'+str(i)):\n",
    "                feat_map = tf.layers.conv2d(feat_map,filters=n_filters[i],kernel_size=[1,1],kernel_regularizer=regularizer)\n",
    "                feat_map = tf.nn.leaky_relu(feat_map,alpha=.25)\n",
    "    return feat_map\n",
    "\n",
    "def depth_selection(model):\n",
    "    with tf.variable_scope('stack_v'):\n",
    "        v1 = tf.identity(model['vgg_16/conv5/conv5_1'],name='v1')\n",
    "        v1 = add_1by1_conv(v1,n_layers=3,n_filters=[1024,1024,1024],name='v1',regularizer=regularizer)\n",
    "        size = v1.get_shape().as_list()[1:3]\n",
    "        resize_method = tf.image.ResizeMethod.BILINEAR\n",
    "        v2 = tf.identity(model['vgg_16/conv5/conv5_3'],name='v2')\n",
    "        #v2 = tf.image.resize_images(v2, size, method=resize_method)\n",
    "        v2 = add_1by1_conv(v2,n_layers=3,n_filters=[1024,1024,1024],name='v2',regularizer=regularizer)\n",
    "        v3 = tf.identity(model['vgg_16/conv4/conv4_1'],name='v3')\n",
    "        v3 = tf.image.resize_images(v3, size, method=resize_method)\n",
    "        v3 = add_1by1_conv(v3,n_layers=3,n_filters=[1024,1024,1024],name='v3',regularizer=regularizer)\n",
    "        v4 = tf.identity(model['vgg_16/conv4/conv4_3'],name='v4')\n",
    "        v4 = tf.image.resize_images(v4, size, method=resize_method)\n",
    "        v4 = add_1by1_conv(v4,n_layers=3,n_filters=[1024,1024,1024],name='v4',regularizer=regularizer)\n",
    "        v_all = tf.stack([v1,v2,v3,v4], axis=3)\n",
    "        v_all = tf.reshape(v_all,[-1,v_all.shape[1]*v_all.shape[2],v_all.shape[3],v_all.shape[4]])\n",
    "        v_all = tf.nn.l2_normalize(v_all, axis=-1, name='stacked_image_feature_maps')\n",
    "    return v_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1024 11:17:15.478177 140192113698624 deprecation_wrapper.py:119] From /home/hassan/CVPR_final/v0_final/codes/utils.py:300: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Visual Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1024 11:17:16.646660 140192113698624 deprecation.py:323] From <ipython-input-2-e21064ea4eb8>:189: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W1024 11:17:16.649092 140192113698624 deprecation.py:506] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1024 11:17:16.990737 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/module.py:104: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1024 11:17:16.991722 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/resolver.py:73: The name tf.logging.log_first_n is deprecated. Please use tf.compat.v1.logging.log_first_n instead.\n",
      "\n",
      "W1024 11:17:16.992434 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/resolver.py:73: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
      "\n",
      "W1024 11:17:16.993196 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/resolver.py:409: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "W1024 11:17:16.994062 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/native_module.py:102: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W1024 11:17:17.005246 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/saved_model_lib.py:70: The name tf.saved_model.constants.SAVED_MODEL_FILENAME_PB is deprecated. Please use tf.saved_model.SAVED_MODEL_FILENAME_PB instead.\n",
      "\n",
      "W1024 11:17:17.042845 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/saved_model_lib.py:160: The name tf.saved_model.constants.ASSETS_KEY is deprecated. Please use tf.saved_model.ASSETS_KEY instead.\n",
      "\n",
      "W1024 11:17:17.045224 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/saved_model_lib.py:45: The name tf.saved_model.constants.VARIABLES_DIRECTORY is deprecated. Please use tf.saved_model.VARIABLES_DIRECTORY instead.\n",
      "\n",
      "W1024 11:17:17.045951 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/saved_model_lib.py:46: The name tf.saved_model.constants.VARIABLES_FILENAME is deprecated. Please use tf.saved_model.VARIABLES_FILENAME instead.\n",
      "\n",
      "W1024 11:17:17.046708 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/module.py:307: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "W1024 11:17:17.048237 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/native_module.py:380: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Text Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1024 11:17:17.590759 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/native_module.py:388: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W1024 11:17:17.602658 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/native_module.py:338: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "W1024 11:17:17.785053 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/native_module.py:342: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W1024 11:17:17.785989 140192113698624 deprecation_wrapper.py:119] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow_hub/native_module.py:345: The name tf.train.SaverDef is deprecated. Please use tf.compat.v1.train.SaverDef instead.\n",
      "\n",
      "W1024 11:17:18.326977 140192113698624 deprecation.py:323] From <ipython-input-3-b01133af2403>:39: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W1024 11:17:19.693660 140192113698624 deprecation.py:323] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "mode = tf.placeholder(tf.string, name='mode')\n",
    "isTraining = tf.equal(mode, 'train')\n",
    "regularizer = tf.contrib.layers.l2_regularizer(reg_val)\n",
    "\n",
    "with tf.device('/gpu:1'):\n",
    "    #building visual model\n",
    "    print('Building Visual Model...')\n",
    "    input_img = tf.placeholder(tf.float32, (None,299,299,3), name='input_img')\n",
    "    pre_processed_img = pre_process(input_img, 'vgg_preprocessing')\n",
    "    vis_model = pre_trained_load(model_name='vgg_16', image_shape=(None,299,299,3),\n",
    "                              input_tensor=pre_processed_img, session=sess, is_training=False, global_pool=True)\n",
    "\n",
    "    v = depth_selection(vis_model) #(?,1225,4,1024)\n",
    "    \n",
    "   #building text model\n",
    "    print('Building Text Model...')\n",
    "    #sentence placeholder - list of sentences\n",
    "    text_batch = tf.placeholder('string', shape=[None], name='text_input')\n",
    "    #loading pre-trained ELMo\n",
    "    elmo = hub.Module(\"../modules/ELMo\", trainable=True)\n",
    "    #getting ELMo embeddings\n",
    "    elmo_embds = elmo(text_batch, signature=\"default\", as_dict=True)\n",
    "    lstm1_embd = elmo_embds['lstm_outputs1'] #?xTXD\n",
    "    lstm2_embd = elmo_embds['lstm_outputs2'] #?xTXD\n",
    "    w_embd = tf.identity(elmo_embds['elmo'], name='elmo_word_embd') #?xTXD\n",
    "    #taking index of last word in each sentence\n",
    "    idx = elmo_embds['sequence_len']-1\n",
    "    batch_idx = tf.stack([tf.range(0,tf.size(idx),1),idx],axis=1)\n",
    "    # Concatenate first of backward with last of forward to get sentence embeddings\n",
    "    dim = lstm1_embd.get_shape().as_list()[-1]\n",
    "    sen_embd_1 = tf.concat([lstm1_embd[:,0,int(dim/2):],\n",
    "                            tf.gather_nd(lstm1_embd[:,:,:int(dim/2)],batch_idx)], axis=-1) #[batch,dim]\n",
    "    sen_embd_2 = tf.concat([lstm2_embd[:,0,int(dim/2):],\n",
    "                            tf.gather_nd(lstm2_embd[:,:,:int(dim/2)],batch_idx)], axis=-1) #[batch,dim]\n",
    "    sen_embd = tf.concat([tf.expand_dims(sen_embd_1,axis=2),\n",
    "                               tf.expand_dims(sen_embd_2,axis=2)], axis=2, name='elmo_sen_embd') #[batch,dim,2]\n",
    "    e_s = tf.layers.dense(sen_embd,units=1,use_bias=False) #?xDx1\n",
    "    e_s = tf.squeeze(e_s,axis=2)\n",
    "    e_s = tf.layers.dense(e_s, units=1024)\n",
    "    e_s = tf.nn.leaky_relu(e_s,alpha=.25)\n",
    "    e_s = tf.layers.dense(e_s, units=1024)\n",
    "    e_s = tf.nn.leaky_relu(e_s,alpha=.25)\n",
    "    e_s = tf.nn.l2_normalize(e_s, axis=-1, name='sen_embedding')\n",
    "        \n",
    "    e_w = tf.layers.dense(w_embd, units=1024)\n",
    "    e_w = tf.nn.leaky_relu(e_w,alpha=.25)\n",
    "    e_w = tf.layers.dense(e_w, units=1024)\n",
    "    e_w = tf.nn.leaky_relu(e_w,alpha=.25)\n",
    "    e_w = tf.nn.l2_normalize(e_w, axis=-1, name='w_embedding')\n",
    "    \n",
    "    heatmap_w,heatmap_s,R_i,R_s = attn(e_w,v,e_s)\n",
    "        \n",
    "loss = attn_loss(e_w,v,e_s) + tf.losses.get_regularization_loss()\n",
    "loss = tf.identity(loss, name='loss')\n",
    "        \n",
    "lr = tf.placeholder(tf.float32, shape=[], name='learning_rate')\n",
    "opt = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "train_vars = list(set(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)) - set(vis_model.model_weights))\n",
    "train_op = opt.minimize(loss, var_list=train_vars, name='train_op')\n",
    "\n",
    "global_saver = tf.train.Saver()\n",
    "    \n",
    "train_writer = tf.summary.FileWriter('./logs/vgg/mscoco', sess.graph)\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1024 11:17:39.442469 140192113698624 deprecation.py:323] From /home/hassan/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading visual path model (vgg)...\n",
      "Start training...\n",
      "\n",
      "\n",
      "=====Epoch: 0\n",
      "===Train\n",
      "Sample 82720/82752, train_loss:7.4928  \n",
      "===Validation\n",
      "Sample 500/500, IoU_acc:0.30, Hit_acc:0.58 \n",
      "Hit accuracy improved. Saving best model...\n",
      "\n",
      "IoU accuracy improved. Saving best model...\n",
      "\n",
      "\n",
      "=====Epoch: 1\n",
      "===Train\n",
      "Sample 82720/82752, train_loss:6.1617 \n",
      "===Validation\n",
      "Sample 500/500, IoU_acc:0.31, Hit_acc:0.57 \n",
      "IoU accuracy improved. Saving best model...\n",
      "\n",
      "\n",
      "=====Epoch: 2\n",
      "===Train\n",
      "Sample 48736/82752, train_loss:5.8542 \r"
     ]
    }
   ],
   "source": [
    "condition = 'ELMo_VGG_MSCOCO'\n",
    "print('Initializing...')\n",
    "_ = sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "#loading pretrained vgg weights\n",
    "print('Loading visual path model (vgg)...')\n",
    "vis_model.load_weights()\n",
    "    \n",
    "#loop on training data\n",
    "print('Start training...')\n",
    "iou_acc = np.zeros((n_epochs,))\n",
    "hit_acc = np.zeros((n_epochs,))\n",
    "train_loss = np.zeros((n_epochs,))\n",
    "lr_value_0 = .001\n",
    "max_val_iou = 0\n",
    "max_val_hit = 0\n",
    "for e in range(n_epochs):\n",
    "    print('\\n\\n=====Epoch: %d'%e)\n",
    "    avg_loss = 0\n",
    "    if e<9:\n",
    "        lr_value=lr_value_0\n",
    "    elif 9<=e<14:\n",
    "        lr_value=lr_value_0/2.0\n",
    "    elif e>=14:\n",
    "        lr_value=lr_value_0/4.0\n",
    "        \n",
    "    print('===Train')\n",
    "    for i in range(n_iter_per_epoch):\n",
    "        img_batch, cap_batch = batch_gen(ids_train, dict_train, txn)\n",
    "        feed_dict = {input_img: img_batch, text_batch: cap_batch, mode: 'train', lr: lr_value}\n",
    "        summary, loss_val, _ = sess.run([merged, loss, train_op], feed_dict)\n",
    "        if i%100==0:\n",
    "            train_writer.add_summary(summary, n_iter_per_epoch*e + i)\n",
    "        avg_loss+=loss_val\n",
    "        var = [i*n_batch, n_iter_per_epoch*n_batch, avg_loss/float(i+1)]\n",
    "        prnt = 'Sample {}/{}, train_loss:{:.4f} \\r'.format(var[0],var[1],var[2])\n",
    "        sys.stdout.write(prnt)                \n",
    "        sys.stdout.flush()     \n",
    "    train_loss[e] = avg_loss/float(n_iter_per_epoch+1)\n",
    "    \n",
    "    #validation phase\n",
    "    print('\\n===Validation')\n",
    "    iou_acc[e],hit_acc[e]=validate_flickr30k(dict_val)\n",
    "    sv = 'Epoch:{}, Train_loss:{}, Val_iou_acc:{}, Val_hit_acc:{}\\r'.format(e,train_loss[e],iou_acc[e],hit_acc[e])\n",
    "    open('./logs/log_'+condition+'.txt', 'w').write(sv)\n",
    "    if hit_acc[e]>max_val_hit:\n",
    "        max_val_hit = hit_acc[e]\n",
    "        print('\\nHit accuracy improved. Saving best model...\\r')\n",
    "        global_saver.save(sess, '../saved_models/model_'+condition+'_best_hit')\n",
    "    if iou_acc[e]>max_val_iou:\n",
    "        max_val_iou = iou_acc[e]\n",
    "        print('\\nIoU accuracy improved. Saving best model...\\r')\n",
    "        global_saver.save(sess, '../saved_models/model_'+condition+'_best_iou')\n",
    "        \n",
    "print('\\n\\nTraining done.')\n",
    "#saving the session\n",
    "print('Saving model...')\n",
    "global_saver.save(sess, '../saved_models/model_'+condition)\n",
    "print('Saving done.')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label='Train loss '+condition)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(100.*iou_acc, label='Validation iou_acc '+condition)\n",
    "plt.plot(100.*hit_acc, label='Validation hit_acc '+condition)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
